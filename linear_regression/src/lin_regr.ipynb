{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import sqrt\n",
    "import os\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(\"lin_regr.ipynb\")), os.pardir))\n",
    "data_folder = \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay_causes = []\n",
    "columns = []\n",
    "target_variable = \"DEP_DELAY\"\n",
    "target_col = []"
   ]
  },
  {
   "source": [
    "Считывание данных из файла в array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(notebook_path + data_folder + '2017.csv', newline='\\n') as csv_file:\n",
    "\tcsv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\tline_count = 0\n",
    "\tfor row in csv_reader:\n",
    "\t\tif line_count == 0:\n",
    "\t\t\tcolumns = row.copy()\n",
    "\t\t\tline_count += 1\n",
    "\t\telse:\n",
    "\t\t\tairline_delay_causes.append(row)\n",
    "\t\t\tline_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0   YEAR\n1   MONTH\n2   DAY_OF_MONTH\n3   DAY_OF_WEEK\n4   OP_UNIQUE_CARRIER\n5   TAIL_NUM\n6   OP_CARRIER_FL_NUM\n7   ORIGIN\n8   DEST\n9   CRS_DEP_TIME\n10   DEP_TIME\n11   DEP_DELAY\n12   TAXI_OUT\n13   TAXI_IN\n14   CRS_ARR_TIME\n15   ARR_TIME\n16   ARR_DELAY\n17   CANCELLED\n18   CANCELLATION_CODE\n19   DIVERTED\n20   CRS_ELAPSED_TIME\n21   ACTUAL_ELAPSED_TIME\n22   AIR_TIME\n23   FLIGHTS\n24   DISTANCE\n25   CARRIER_DELAY\n26   WEATHER_DELAY\n27   NAS_DELAY\n28   SECURITY_DELAY\n29   LATE_AIRCRAFT_DELAY\n30   \n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    print(columns.index(col), \" \", col)"
   ]
  },
  {
   "source": [
    "Отбор необходимых признаков, отбрасывание столбцов, у которых эти фичи находятся без значения"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "489170"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "target_index = 11\n",
    "# features = [1, 2, 9, 10, 12, 17, 19, 25, 26, 27, 28, 29]\n",
    "features = [1, 2, 9, 10, 17, 19]\t\t# это фичи, которые можно использовать для предсказания подлета, еще не совершенного\n",
    "data_train_features = []\n",
    "data_train_target = []\n",
    "for row in airline_delay_causes:\n",
    "\ttmp = []\n",
    "\tfor col in features:\n",
    "\t\tif len(row[col]) == 0:\n",
    "\t\t\tbreak\n",
    "\t\tif len(row[target_index]) == 0:\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\ttmp.append(float(row[col]))\n",
    "\tif len(tmp) == len(features):\n",
    "\t\tdata_train_features.append(tmp)\n",
    "\t\tdata_train_target.append(float(row[target_index]))\n",
    "len(data_train_features)"
   ]
  },
  {
   "source": [
    "Функции линейной алгебры"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(V):\n",
    "    ans = 0\n",
    "    for i in V:\n",
    "        ans += i**2\n",
    "    return sqrt(ans)\n",
    "\n",
    "def sumvc(X, a):\n",
    "    ans = X.copy()\n",
    "    for i in range(len(X)):\n",
    "        ans[i] += a\n",
    "    return ans\n",
    "\n",
    "def sumvv(X, Y):\n",
    "    if len(X) != len(Y):\n",
    "        raise Exception(\"Len of vectors should be same!\")\n",
    "    ans = X.copy()\n",
    "    for i in range(len(Y)):\n",
    "        ans[i] += Y[i]\n",
    "    return ans\n",
    "\n",
    "def subvc(X, a):\n",
    "    ans = X.copy()\n",
    "    for i in range(len(X)):\n",
    "        ans[i] -= a\n",
    "    return ans\n",
    "\n",
    "def subvv(X, Y):\n",
    "    if len(X) != len(Y):\n",
    "        raise Exception(\"Len of vectors should be same!\")\n",
    "    ans = X.copy()\n",
    "    for i in range(len(Y)):\n",
    "        ans[i] -= Y[i]\n",
    "    return ans\n",
    "\n",
    "def multvc(X, c):\n",
    "    ans = X.copy()\n",
    "    for i in range(len(X)):\n",
    "        ans[i] *= c\n",
    "    return ans\n",
    "\n",
    "def multvv(X, Y):\n",
    "    if len(X) != len(Y):\n",
    "        raise Exception(\"Len of vectors should be same!\")\n",
    "    ans = X.copy()\n",
    "    for i in range(len(Y)):\n",
    "        ans[i] *= Y[i]\n",
    "    return ans\n",
    "\n",
    "def dotvv(X, Y):\n",
    "    if len(X) != len(Y):\n",
    "        raise Exception(\"Len of vectors should be same!\")\n",
    "    ans = 0\n",
    "    for i in range(len(X)):\n",
    "        ans += X[i] * Y[i]\n",
    "    return ans\n",
    "\n",
    "def summc(A, c):\n",
    "    if len(A) == 0:\n",
    "        return []\n",
    "    rows_A = len(A)\n",
    "    cols_A = len(A[0])\n",
    "    ans = [[0 for row in range(cols_A)] for col in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_A):\n",
    "            ans[i][j] = A[i][j] + c\n",
    "    return ans\n",
    "\n",
    "def summm(A, B):\n",
    "    if len(A) == 0 or len(B) == 0:\n",
    "        return []\n",
    "    if len(A) != len(B) or len(A[0]) != len(B[0]):\n",
    "        raise Exception(\"Dim of matrix should be same!\")\n",
    "    rows_A = len(A)\n",
    "    cols_B = len(B[0])\n",
    "    ans = [[0 for row in range(cols_B)] for col in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            ans[i][j] = A[i][j] + B[i][j]\n",
    "    return ans\n",
    "\n",
    "def submc(A, c):\n",
    "    if len(A) == 0:\n",
    "        return []\n",
    "    rows_A = len(A)\n",
    "    cols_A = len(A[0])\n",
    "    ans = [[0 for row in range(cols_A)] for col in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_A):\n",
    "            ans[i][j] = A[i][j] - c\n",
    "    return ans\n",
    "\n",
    "def submm(A, B):\n",
    "    if len(A) == 0 or len(B) == 0:\n",
    "        return []\n",
    "    if len(A) != len(B) or len(A[0]) != len(B[0]):\n",
    "        raise Exception(\"Dim of matrix should be same!\")\n",
    "    rows_A = len(A)\n",
    "    cols_B = len(B[0])\n",
    "    ans = [[0 for row in range(cols_B)] for col in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            ans[i][j] = A[i][j] - B[i][j]\n",
    "    return ans\n",
    "\n",
    "def multmc(A, c):\n",
    "    if len(A) == 0:\n",
    "        return []\n",
    "    rows_A = len(A)\n",
    "    cols_A = len(A[0])\n",
    "    ans = [[0 for col in range(cols_A)] for row in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_A):\n",
    "            ans[i][j] = A[i][j] * c\n",
    "    return ans\n",
    "\n",
    "def multmv(A, V):\n",
    "    if len(A) == 0:\n",
    "        return []\n",
    "    rows_A = len(A)\n",
    "    cols_A = len(A[0])\n",
    "    rows_V = len(V)\n",
    "    if cols_A != rows_V:\n",
    "        raise Exception(\"Cannot multiply the matrix and vector. Incorrect dimensions.\")\n",
    "    ans = [0 for row in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_A):\n",
    "            ans[i] += A[i][j] * V[j]\n",
    "    return ans\n",
    "\n",
    "def multmm(A, B):\n",
    "    if len(A) == 0 or len(B) == 0:\n",
    "        return []\n",
    "    rows_A = len(A)\n",
    "    cols_A = len(A[0])\n",
    "    rows_B = len(B)\n",
    "    cols_B = len(B[0])\n",
    "    if cols_A != rows_B:\n",
    "        raise Exception(\"Cannot multiply the two matrices. Incorrect dimensions.\")\n",
    "    ans = [[0 for row in range(cols_B)] for col in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            for k in range(cols_A):\n",
    "                ans[i][j] += A[i][k] * B[k][j]\n",
    "    return ans\n",
    "\n",
    "def decvc(V, c):\n",
    "    ans = V.copy()\n",
    "    for i in range(len(V)):\n",
    "        ans[i] /= c\n",
    "    return ans\n",
    "\n",
    "def decvv(V, W):\n",
    "    ans = V.copy()\n",
    "    for i in range(len(V)):\n",
    "        ans[i] /= W[i]\n",
    "    return ans\n",
    "\n",
    "def sqrtv(V):\n",
    "    ans = V.copy()\n",
    "    for i in range(len(V)):\n",
    "        ans[i] = sqrt(ans[i])\n",
    "    return ans\n",
    "\n",
    "def powv(V, s):\n",
    "    if s == 0:\n",
    "        return [1 for el in range(len(V))]\n",
    "    tmp = powv(V, int(s/2))\n",
    "    if s % 2 == 0:\n",
    "        return multvv(tmp, tmp)\n",
    "    else:\n",
    "        return multvv(multvv(tmp, tmp), V)"
   ]
  },
  {
   "source": [
    "Функции метрик"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(W, X, Y, alpha=None):\n",
    "    if len(X[0]) != len(W) or len(X) != len(Y):\n",
    "        raise Exception(\"Len of vectors should be same!\")\n",
    "    ans = 0\n",
    "    for i in range(len(X)):\n",
    "        ans += ((dotvv(W, X[i]) - Y[i])**2)/len(X)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absv(V):\n",
    "    ans = V.copy()\n",
    "    for i in range(len(V)):\n",
    "        if ans[i] < 0:\n",
    "            ans[i] = -ans[i]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_l1(W, X, Y, alpha):\n",
    "\tif len(X[0]) != len(W) or len(X) != len(Y):\n",
    "\t\traise Exception(\"Len of vectors should be same!\")\n",
    "\tans = 0\n",
    "\tfor i in range(len(X)):\n",
    "\t\tans += ((dotvv(W, X[i]) - Y[i])**2)/len(X)\n",
    "\treturn ans + (alpha*sum(absv(W)))/len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_l2(W, X, Y, alpha):\n",
    "\tif len(X[0]) != len(W) or len(X) != len(Y):\n",
    "\t\traise Exception(\"Len of vectors should be same!\")\n",
    "\tans = 0\n",
    "\tfor i in range(len(X)):\n",
    "\t\tans += ((dotvv(W, X[i]) - Y[i])**2)/len(X)\n",
    "\treturn ans + (alpha*sum(powv(W, 2)))/len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(W, X, Y):\n",
    "\tif len(X[0]) != len(W) or len(X) != len(Y):\n",
    "\t\traise Exception(\"Len of vectors should be same!\")\n",
    "\tym = sum(Y)/len(Y)\n",
    "\tSSreg = 0\n",
    "\tfor i in range(len(X)):\n",
    "\t\tSSreg += (dotvv(W, X[i]) - ym)**2\n",
    "\tSStot = 0\n",
    "\tfor i in range(len(Y)):\n",
    "\t\tSStot += (Y[i] - ym)**2\n",
    "\treturn 1 - (SSreg / SStot)"
   ]
  },
  {
   "source": [
    "Функции градиентного спуска"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(method, h, W, X, Y, alpha):\n",
    "\tcol_X = len(X[0])\n",
    "\tans = [0 for i in range(col_X)]\n",
    "\tWn = W.copy()\n",
    "\tfor i in range(col_X):\n",
    "\t\tWn[i] += h\n",
    "\t\tans[i] = (method(Wn, X, Y, alpha) - method(W, X, Y, alpha))/h\n",
    "\t\tWn[i] -= h\n",
    "\treturn ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquareMethod(method, A, y, alpha, beta=None, gamma=None):\n",
    "    col_A = len(A[0])\n",
    "    W = [1. for row in range(col_A)]\n",
    "    step = 1e-8\n",
    "    h = 1e-8\n",
    "    L = 0\n",
    "    Lnew = method(W, A, y, alpha)\n",
    "    num_steps = 2000\n",
    "    while abs(L - Lnew) > 1e-6 and num_steps > 0:\n",
    "        L = Lnew\n",
    "        W = subvv(W, multvc(grad(method, h, W, A, y, alpha), step))\n",
    "        Lnew = method(W, A, y, alpha)\n",
    "        num_steps -= 1\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(method, A, y, alpha=None, beta=None, gamma=None):\n",
    "\tcol_A = len(A[0])\n",
    "\tW = [1. for row in range(col_A)]\n",
    "\tstep = 1e-8\n",
    "\th = 1e-8\n",
    "\tL = 0\n",
    "\tLnew = method(W, A, y, alpha)\n",
    "\tnum_steps = 50\n",
    "\twhile abs(L - Lnew) > 1e-5 and num_steps > 0:\n",
    "\t\tfor i in range(len(A)):\n",
    "\t\t\tL = Lnew\n",
    "\t\t\tW = subvv(W, multvc(grad(method, h, W, [A[i]], [y[i]], alpha), step))\n",
    "\t\t\tLnew = method(W, A, y, alpha)\n",
    "\t\tnum_steps -= 1\n",
    "\treturn W"
   ]
  },
  {
   "source": [
    "def AdaGrad(method, A, y, alpha=None, beta=None, gamma=None):\n",
    "\tcol_A = len(A[0])\n",
    "\tW = [1. for row in range(col_A)]\n",
    "\tstep = 1e-1\n",
    "\th = 1e-2\n",
    "\teps = 1\n",
    "\tL = method(W, A, y, alpha)\n",
    "\tGnii = [0 for i in range(col_A)]\n",
    "\ttemp = grad(method, h, W, A, y, alpha)\n",
    "\tfor i in range(col_A):\n",
    "\t\tGnii[i] = (temp[i])**2\n",
    "\t\tW[i] -= step*temp[i]/sqrt(Gnii[i] + eps)\n",
    "\tLnew = method(W, A, y, alpha)\n",
    "\tnum_steps = 2500\n",
    "\twhile abs(L - Lnew) > 1e-1 and num_steps > 0:\n",
    "\t\tL = Lnew\n",
    "\t\ttemp = grad(method, h, W, A, y, alpha)\n",
    "\t\tfor i in range(col_A):\n",
    "\t\t\tGnii[i] += (temp[i])**2\n",
    "\t\t\tW[i] -= step*temp[i]/sqrt(Gnii[i] + eps)\n",
    "\t\tLnew = method(W, A, y, alpha)\n",
    "\t\tnum_steps -= 1\n",
    "\treturn W"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSProp(method, A, y, alpha=None, beta=None, gamma=0.5):\n",
    "    if gamma is None:\n",
    "        gamma = 0.5\n",
    "    col_A = len(A[0])\n",
    "    W = [1. for row in range(col_A)]\n",
    "    step = 1e-3\n",
    "    h = 1e-3\n",
    "    eps = 1e-3\n",
    "    L = method(W, A, y, alpha)\n",
    "    Eg = 0\n",
    "    tmp = 0\n",
    "    tmpnew = grad(method, h, W, A, y, alpha)\n",
    "    Eg = multvc(powv(tmpnew, 2), 1-gamma)\n",
    "    W = subvv(W, decvv(multvc(tmpnew, step), sqrtv(sumvc(Eg, eps))))\n",
    "    Lnew = method(W, A, y, alpha)\n",
    "    num_steps = 3500\n",
    "    while abs(L - Lnew) > 1e-2 and num_steps > 0:\n",
    "        L = Lnew\n",
    "        tmp = tmpnew\n",
    "        tmpnew = grad(method, h, W, A, y, alpha)\n",
    "        Eg = sumvv(multvc(powv(tmp, 2), gamma), multvc(powv(tmpnew, 2), 1-gamma))\n",
    "        W = subvv(W, decvv(multvc(tmpnew, step), sqrtv(sumvc(Eg, eps))))\n",
    "        Lnew = method(W, A, y, alpha)\n",
    "        num_steps -= 1\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam(method, A, y, alpha=None, gamma=0.9, beta=[0.95, 0.95]):\n",
    "\tif gamma is None:\n",
    "\t\tgamma = 0.9\n",
    "\tif beta is None:\n",
    "\t\tbeta=[0.95, 0.95]\n",
    "\tcol_A = len(A[0])\n",
    "\tW =[1. for row in range(col_A)]\n",
    "\tstep = 1e-4\n",
    "\th = 1e-3\n",
    "\teps = 1e-3\n",
    "\tL = 0\n",
    "\tLnew = method(W, A, y, alpha)\n",
    "\ttmp = grad(method, h, W, A, y, alpha)\n",
    "\tmt = multvc(tmp, 1-beta[0])\n",
    "\t_mt = decvc(mt, 1-beta[0])\n",
    "\tvt = multvc(powv(tmp, 2), 1-beta[1])\n",
    "\t_vt = decvc(vt, 1-beta[1])\n",
    "\tW = subvv(W, decvv(multvc(_mt, step), sqrtv(sumvc(_vt, eps))))\n",
    "\tL = Lnew\n",
    "\tLnew = method(W, A, y, alpha)\n",
    "\tnum_steps = 4000\n",
    "\twhile abs(L - Lnew) > 1e-3 and num_steps > 0:\n",
    "\t\tL = Lnew\n",
    "\t\ttmp = grad(method, h, W, A, y, alpha)\n",
    "\t\tmt = sumvv(multvc(mt, beta[0]), multvc(tmp, 1-beta[0]))\n",
    "\t\t_mt = decvc(mt, 1-beta[0])\n",
    "\t\tvt = sumvv(multvc(vt, beta[1]), multvc(powv(tmp, 2), 1-beta[1]))\n",
    "\t\t_vt = decvc(vt, 1-beta[1])\n",
    "\t\tW = subvv(W, decvv(multvc(_mt, step), sqrtv(sumvc(_vt, eps))))\n",
    "\t\tLnew = method(W, A, y, alpha)\n",
    "\t\tnum_steps -= 1\n",
    "\treturn W"
   ]
  },
  {
   "source": [
    "Проверка работы написанных методов"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (LSM) =  [0.9953843333362329, 0.9912764970722492, -0.030234118632279205, 0.026670810119412636, 0.9999973371586748, 0.9999944317225982]\nLSM MSE (train) =  2002.2457050078795\nLSM R2  (train) =  0.9754301989008686\nLSM MSE (test) =  3874.707710694763\nLSM R2  (test) =  0.9523828784925616\n"
     ]
    }
   ],
   "source": [
    "W = LeastSquareMethod(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (LSM) = \", W)\n",
    "print(\"LSM MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"LSM R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"LSM MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"LSM R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (LSM) =  [0.9953816957779509, 0.9912738908642496, -0.030235705838322247, 0.02667242335883202, 0.999994669784428, 0.9999917671279945]\nLSM MSE (train) =  2002.2425789832391\nLSM R2  (train) =  0.9754282678195829\nLSM MSE (test) =  3874.723609692847\nLSM R2  (test) =  0.952380209826508\n"
     ]
    }
   ],
   "source": [
    "W = LeastSquareMethod(MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (LSM) = \", W)\n",
    "print(\"LSM MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"LSM R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"LSM MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"LSM R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (SGD) =  [0.976745509449176, 0.9568801035587158, -0.04171559135752234, 0.031773751398039396, 0.9999333369902406, 0.9999122878904186]\nSGD MSE (train) =  2083.540037125873\nSGD R2  (train) =  0.9411089406417071\nSGD MSE (test) =  4269.506835207454\nSGD R2  (test) =  0.8602281538817897\n"
     ]
    }
   ],
   "source": [
    "W = SGD(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (SGD) = \", W)\n",
    "print(\"SGD MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"SGD R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"SGD MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"SGD R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (SGD) =  [0.976681191682568, 0.956817777025685, -0.0417173968673723, 0.03177632594750812, 0.9998666762864902, 0.9998456290556169]\nSGD MSE (train) =  2083.5288337626425\nSGD R2  (train) =  0.9411070938475075\nSGD MSE (test) =  4269.5337636149525\nSGD R2  (test) =  0.8602219440403742\n"
     ]
    }
   ],
   "source": [
    "W = SGD(MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (SGD) = \", W)\n",
    "print(\"SGD MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"SGD R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"SGD MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"SGD R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (AdaGrad) =  [0.012829392561839447, 0.01288933872790098, 0.00253380175602242, 0.004635717533088014, -0.004999999999930781, -0.011191199387971695]\nAdaGrad MSE (train) =  2008.6059753656036\nAdaGrad R2  (train) =  0.9922200033464981\nAdaGrad MSE (test) =  3773.6001646355617\nAdaGrad R2  (test) =  0.9330717935904191\n"
     ]
    }
   ],
   "source": [
    "W = AdaGrad(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (AdaGrad) = \", W)\n",
    "print(\"AdaGrad MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"AdaGrad R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"AdaGrad MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"AdaGrad R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (AdaGrad) =  [0.012846934300439136, 0.012898564238540884, 0.002533758474932849, 0.004635676121061766, 0.0454594756634639, -0.012611935473927319]\nAdaGrad MSE (train) =  2008.6063164073314\nAdaGrad R2  (train) =  0.9922200843895486\nAdaGrad MSE (test) =  3773.5995550703256\nAdaGrad R2  (test) =  0.9330735887075834\n"
     ]
    }
   ],
   "source": [
    "W = AdaGrad(MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (AdaGrad) = \", W)\n",
    "print(\"AdaGrad MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"AdaGrad R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"AdaGrad MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"AdaGrad R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (RMSProp) =  [-0.12345490214943651, 0.02291121459752586, -0.04038965481951087, 0.04853582649719525, -1.4266020246148374e-05, -0.0007839453149997187]\nRMSProp MSE (train) =  1919.2287152145186\nRMSProp R2  (train) =  0.941051961165688\nRMSProp MSE (test) =  4147.3847840811295\nRMSProp R2  (test) =  0.8765054874327615\n"
     ]
    }
   ],
   "source": [
    "W = RMSProp(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (RMSProp) = \", W)\n",
    "print(\"RMSProp MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"RMSProp R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (RMSProp) =  [-0.12345490214943651, 0.02291121459752586, -0.04038965481951087, 0.04853582649719525, -1.4266020246148374e-05, -0.0007839453149997187]\nRMSProp MSE (train) =  1919.2287152145186\nRMSProp R2  (train) =  0.941051961165688\nRMSProp MSE (test) =  4147.3847840811295\nRMSProp R2  (test) =  0.8765054874327615\n"
     ]
    }
   ],
   "source": [
    "W = RMSProp(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)\n",
    "print(\"\\nW (RMSProp) = \", W)\n",
    "print(\"RMSProp MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"RMSProp R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (RMSProp) =  [-0.13601346139452763, 0.029329372325142718, -0.040391212164295816, 0.04853953224299829, -0.0004997677978625556, -0.3571148411921018]\nRMSProp MSE (train) =  1919.1887049590537\nRMSProp R2  (train) =  0.9410425334980366\nRMSProp MSE (test) =  4146.81853723521\nRMSProp R2  (test) =  0.876670886311853\n"
     ]
    }
   ],
   "source": [
    "W = RMSProp(MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha=0.5)\n",
    "print(\"\\nW (RMSProp) = \", W)\n",
    "print(\"RMSProp MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"RMSProp MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"RMSProp R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (Adam) =  [-0.0014514810513464906, -0.0007954289511370477, -0.0033788423049536708, 0.009847559972595444, -0.0005251126123069441, -0.0008164709046152803]\nAdam MSE (train) =  1988.775701209403\nAdam R2  (train) =  0.9927080286383675\nAdam MSE (test) =  3841.559863687825\nAdam R2  (test) =  0.9213593546271185\n"
     ]
    }
   ],
   "source": [
    "W = Adam(MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha=0.95, gamma=0.95, beta=[0.95, 0.95])\n",
    "print(\"\\nW (Adam) = \", W)\n",
    "print(\"Adam MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"Adam R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"Adam MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"Adam R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW (Adam) =  [-0.04658733330257577, -0.019639268272707077, -0.0410710362486944, 0.048225087733778586, 0.003212863772234631, -0.06572414421194928]\nAdam MSE (train) =  1919.2865334050412\nAdam R2  (train) =  0.9441976334835918\nAdam MSE (test) =  4194.796127046099\nAdam R2  (test) =  0.864794574705339\n"
     ]
    }
   ],
   "source": [
    "W = Adam(MSE_l2,data_train_features[:1000], data_train_target[:1000], alpha, gamma=0.95, beta=[0.9, 0.9])\n",
    "print(\"\\nW (Adam) = \", W)\n",
    "print(\"Adam MSE (train) = \", MSE(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"Adam R2  (train) = \", R2(W, data_train_features[:1000], data_train_target[:1000]))\n",
    "print(\"Adam MSE (test) = \", MSE(W, data_train_features[1000:2000], data_train_target[1000:2000]))\n",
    "print(\"Adam R2  (test) = \", R2(W, data_train_features[1000:2000], data_train_target[1000:2000]))"
   ]
  },
  {
   "source": [
    "Функция для кросс-валидации и работа с нею"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(methodGD, methodReg, X, Y, alpha=None, beta=None, gamma=None, folds=5):\n",
    "    Wf = []\n",
    "    onefold = int(1000/folds)\n",
    "    for i in range(folds):\n",
    "        Wf.append(methodGD(methodReg, X[:i*onefold] + X[(i+1)*onefold:], \n",
    "                                      Y[:i*onefold] + Y[(i+1)*onefold:], alpha, beta, gamma))\n",
    "    W = Wf[0].copy()\n",
    "    for i in range(1, len(Wf)):\n",
    "        W = sumvv(W, Wf[i])\n",
    "    W = decvc(W, len(Wf))\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    R2_train = []\n",
    "    R2_test = []\n",
    "    for i in range(folds):\n",
    "        MSE_train.append(MSE(W, X[:i*onefold] + X[(i+1)*onefold:], \n",
    "                                Y[:i*onefold] + Y[(i+1)*onefold:]))\n",
    "        MSE_test.append(MSE(W, X[i*onefold:(i+1)*onefold], \n",
    "                                Y[i*onefold:(i+1)*onefold]))\n",
    "        R2_train.append(R2(W, X[:i*onefold] + X[(i+1)*onefold:], \n",
    "                              Y[:i*onefold] + Y[(i+1)*onefold:]))\n",
    "        R2_test.append(R2(W, X[i*onefold:(i+1)*onefold], \n",
    "                             Y[i*onefold:(i+1)*onefold]))\n",
    "    print(\"\\nW \" + str(methodGD.__name__) + \" (\" + str(methodReg.__name__) + \") = \", W)\n",
    "    print(str(methodGD.__name__) + \" MSE (train) = \", sum(MSE_train)/len(MSE_train))\n",
    "    print(str(methodGD.__name__) + \" R2  (train) = \", sum(R2_train)/len(R2_train))\n",
    "    print(str(methodGD.__name__) + \" MSE (test) = \", sum(MSE_test)/len(MSE_test))\n",
    "    print(str(methodGD.__name__) + \" R2  (test) = \", sum(R2_test)/len(R2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW LeastSquareMethod (MSE_l1) =  [0.995383908286658, 0.9912779703536672, -0.030613017555288023, 0.027035730652460187, 0.999997336441993, 0.9999944260818665]\nLeastSquareMethod MSE (train) =  2001.594267327019\nLeastSquareMethod R2  (train) =  0.9737671627150604\nLeastSquareMethod MSE (test) =  2001.5942673270208\nLeastSquareMethod R2  (test) =  0.9042755820335765\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(LeastSquareMethod, MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha, beta=None, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW LeastSquareMethod (MSE_l2) =  [0.9953812616225605, 0.99127534520062, -0.030614617075889326, 0.027037356308528614, 0.9999946689760236, 0.9999917580243164]\nLeastSquareMethod MSE (train) =  2001.5911740475326\nLeastSquareMethod R2  (train) =  0.9737651429498871\nLeastSquareMethod MSE (test) =  2001.5911740475312\nLeastSquareMethod R2  (test) =  0.9042724935887916\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(LeastSquareMethod, MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha, beta=None, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW SGD (MSE_l1) =  [0.9806418433898759, 0.9642396015495178, -0.045980734772653055, 0.03623279995981854, 0.9999466703660523, 0.9999298905745754]\nSGD MSE (train) =  2073.2126668354704\nSGD R2  (train) =  0.9348610129283822\nSGD MSE (test) =  2073.212666835468\nSGD R2  (test) =  0.8926901298765081\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(SGD, MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha, beta=None, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW SGD (MSE_l2) =  [0.9805901099555848, 0.9641892118229279, -0.045982715414874774, 0.03623539786083185, 0.999893339557579, 0.9998765609789707]\nSGD MSE (train) =  2073.2042156774924\nSGD R2  (train) =  0.934858061281765\nSGD MSE (test) =  2073.2042156774914\nSGD R2  (test) =  0.8926860299885053\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(SGD, MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW AdaGrad (MSE_l1) =  [0.012829467196885536, 0.012890228487844005, 0.0025341230249684606, 0.004634270493881597, -0.004999999998482189, -0.01152603439607442]\nAdaGrad MSE (train) =  2008.6100650561086\nAdaGrad R2  (train) =  0.991613486161538\nAdaGrad MSE (test) =  2008.6100650561068\nAdaGrad R2  (test) =  0.9534157607850471\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(AdaGrad, MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW AdaGrad (MSE_l2) =  [0.012847009097718071, 0.012899457675121332, 0.002534079742210122, 0.004634229042787848, 0.04545947673677503, -0.01278466622165022]\nAdaGrad MSE (train) =  2008.610417748374\nAdaGrad R2  (train) =  0.9916135629813952\nAdaGrad MSE (test) =  2008.6104177483753\nAdaGrad R2  (test) =  0.9534152949951444\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(AdaGrad, MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW RMSProp (MSE_l1) =  [-0.1284688444520517, 0.026553389305338525, -0.04320518843998984, 0.05090781074148994, -1.4266020849052841e-05, -0.0009323455022908307]\nRMSProp MSE (train) =  1919.0092040100085\nRMSProp R2  (train) =  0.9353984826486144\nRMSProp MSE (test) =  1919.0092040100092\nRMSProp R2  (test) =  0.8651947177342535\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(RMSProp, MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW RMSProp (MSE_l2) =  [-0.13329383207825635, 0.02834872417466955, -0.043203303244974754, 0.05091179303308062, -0.0004999999681632409, -0.22174037927381568]\nRMSProp MSE (train) =  1918.979207445915\nRMSProp R2  (train) =  0.9353812053271291\nRMSProp MSE (test) =  1918.9792074459133\nRMSProp R2  (test) =  0.8651590345051391\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(RMSProp, MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW Adam (MSE_l1) =  [-0.015194710012066973, -0.011926254895633119, -0.04130277523941554, 0.04825807441249712, -0.000514904149807688, -0.000729624970722805]\nAdam MSE (train) =  1919.7458905334904\nAdam R2  (train) =  0.9426984012175043\nAdam MSE (test) =  1919.7458905334897\nAdam R2  (test) =  0.8817594467060303\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(Adam, MSE_l1, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nW Adam (MSE_l2) =  [-0.021638483695758333, -0.017726667120012852, -0.04187886296002126, 0.048899452740976936, -0.0005210247401720516, -0.10696604588528]\nAdam MSE (train) =  1919.6237011119113\nAdam R2  (train) =  0.9412125415700465\nAdam MSE (test) =  1919.623701111912\nAdam R2  (test) =  0.8794826483013244\n"
     ]
    }
   ],
   "source": [
    "CrossValidation(Adam, MSE_l2, data_train_features[:1000], data_train_target[:1000], alpha)"
   ]
  },
  {
   "source": [
    "Подход к предсказанию вожможности отложения рейса\n",
    "\n",
    "Найти среднее значение по обучению (delay_yes), которое дает линейная регрессия для таргета, положительного и близкого к нулю.\n",
    "\n",
    "Если значение на тестовой выборке будет больше или равно delay_yes, то предположить, что вылет будет отложен."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(W, X, eps):\n",
    "    return dotvv(W, X) + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.796888239813752\n"
     ]
    }
   ],
   "source": [
    "delay_yes = []\n",
    "for i in data_train_features[:2000]:\n",
    "    if data_train_target[data_train_features.index(i)] < 1.0 and data_train_target[data_train_features.index(i)] >= 0.0:\n",
    "        delay_yes.append(LinearRegression(W, i, 0.0001))\n",
    "delay_yes = sum(delay_yes)/len(delay_yes)\n",
    "print(delay_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(notebook_path + data_folder + 'predict_delay.csv', 'w', newline='\\n') as csvfile:\n",
    "    writ = csv.writer(csvfile, delimiter=',')\n",
    "    cols = []\n",
    "    for i in features:\n",
    "        cols.append(columns[i])\n",
    "    writ.writerow(cols + [\"WILL_BE_DELAYED\"])\n",
    "    for i in data_train_features[2000:]:\n",
    "        tmp = False\n",
    "        if LinearRegression(W, i, 0.0001) >= delay_yes:\n",
    "            tmp = True\n",
    "        writ.writerow(i + [tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}